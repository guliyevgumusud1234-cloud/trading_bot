experiment:
  name: "futures_dqn_1h_test"
  output_dir: "runs"
  seed: 123

log:
  print_freq: 200
  eval_interval: 500
  checkpoint_interval: 1000
  top_k_checkpoints: 1

data:
  csv_path: "data/futures.csv"
  time_col: "timestamp"
  price_col: "close"
  window: 24
  splits:
    train: 0.7
    val: 0.15
    test: 0.15
  purge_bars: 0
  fill_method: "ffill"

environment:
  cost_bps: 1.0
  action_levels: [-1.0, 0.0, 1.0]
  reward_scale: 1.0

model:
  type: "mlp_dueling"
  hidden_sizes: [128, 128]
  dueling: true
  distributional:
    enabled: false
  dropout: 0.0

training:
  device: "cpu"
  max_steps: 2000
  warmup_steps: 400
  batch_size: 64
  gamma: 0.99
  lr: 0.0005
  weight_decay: 0.0
  gradient_clip: 1.0
  epsilon:
    start: 1.0
    end: 0.05
    decay_steps: 1200
  target_update_interval: 400
  eval_episodes: 1
  early_stopping:
    metric: "val_sharpe"
    patience: 4

inference:
  hysteresis_threshold: 0.001
  cooldown_bars: 2
